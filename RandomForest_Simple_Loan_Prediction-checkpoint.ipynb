{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blacklight/MA Advanced Analytics Workbook [Funded Accounts Predictor]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm for Predictive Analytics Project \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## [Simple Bank Marketing Data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Mathematical Libraries & Raw Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing NumPy & SciPy Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Simple Raw Data-Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= \"Raw Data\\RAW_Simple_Report_thru_1.07.2019.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is D00F-3EF0\n",
      "\n",
      " Directory of C:\\Users\\tchopra\\Predictive Analytics Folder\n",
      "\n",
      "01/09/2019  05:20 PM    <DIR>          .\n",
      "01/09/2019  05:20 PM    <DIR>          ..\n",
      "01/09/2019  03:30 PM    <DIR>          .ipynb_checkpoints\n",
      "01/09/2019  03:26 PM            24,779 BankRate_LinearRegression_PredictiveModel.ipynb\n",
      "01/09/2019  03:44 PM    <DIR>          Raw Data\n",
      "01/09/2019  05:20 PM            37,457 Untitled.ipynb\n",
      "               2 File(s)         62,236 bytes\n",
      "               4 Dir(s)  111,393,456,128 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple= pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Snapdhot of Data Set Shape {First 7 Rows}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration & Assessment of Raw Data & Manipulating Time-Stamp on Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working on Getting more info from Time-Stamp of each entry\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_dateinfo(df, date_col, drop=False, time=False, start_ref=pd.datetime(1900, 1, 1), extra_attr = True):\n",
    "    \n",
    "   \n",
    "    df = df.copy()\n",
    "    \n",
    "    # Extract the field\n",
    "    fld = df[date_col]\n",
    "    \n",
    "    # Check the time\n",
    "    fld_dtype = fld.dtype\n",
    "    if isinstance(fld_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n",
    "        fld_dtype = np.datetime64\n",
    "\n",
    "    # Convert to datetime if not already\n",
    "    if not np.issubdtype(fld_dtype, np.datetime64):\n",
    "        df[date_col] = fld = pd.to_datetime(fld, infer_datetime_format=True)\n",
    "    \n",
    "    # Prefix for new columns\n",
    "    pre = re.sub('[Dd]ate', '', date_col)\n",
    "    #pre = re.sub('[Tt]ime', '', pre)\n",
    "    \n",
    "    # Basic attributes\n",
    "    attr = ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear', 'Days_in_month', 'is_leap_year']\n",
    "    \n",
    "    # Additional attributes\n",
    "    if extra_attr:\n",
    "        attr = attr + ['Is_month_end', 'Is_month_start', 'Is_quarter_end', \n",
    "                       'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n",
    "    \n",
    "    # If time is specified, extract time information\n",
    "#     if time: \n",
    "#         attr = attr + ['Hour', 'Minute', 'Second']\n",
    "        \n",
    "    # Iterate through each attribute\n",
    "    for n in attr: \n",
    "        df[pre + n] = getattr(fld.dt, n.lower())\n",
    "        \n",
    "    # Calculate days in year\n",
    "    #df[pre + 'Days_in_year'] = df[pre + 'is_leap_year'] + 365\n",
    "        \n",
    "#     if time:\n",
    "#         # Add fractional time of day (0 - 1) units of day\n",
    "# #         df[pre + 'frac_day'] = ((df[pre + 'Hour']) + (df[pre + 'Minute'] / 60) + (df[pre + 'Second'] / 60 / 60)) / 24\n",
    "        \n",
    "#         # Add fractional time of week (0 - 1) units of week\n",
    "#         df[pre + 'frac_week'] = (df[pre + 'Dayofweek'] + df[pre + 'frac_day']) / 7\n",
    "    \n",
    "#         # Add fractional time of month (0 - 1) units of month\n",
    "#         df[pre + 'frac_month'] = (df[pre + 'Day'] + (df[pre + 'frac_day'])) / (df[pre + 'Days_in_month'] +  1)\n",
    "        \n",
    "#         # Add fractional time of year (0 - 1) units of year\n",
    "#         df[pre + 'frac_year'] = (df[pre + 'Dayofyear'] + df[pre + 'frac_day']) / (df[pre + 'Days_in_year'] + 1)\n",
    "        \n",
    "    # Add seconds since start of reference\n",
    "    #df[pre + 'Elapsed'] = (fld - start_ref).dt.total_seconds()\n",
    "    \n",
    "    if drop: \n",
    "        df = df.drop(date_col, axis=1)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple= extract_dateinfo(simple,\"applied_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11238, 70)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retaining Machine Learning Columns for Automated Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping Columns That will Impact Target Prediction, i.e. Funded_Day_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_v2 = simple.drop([ 'enrolled_7_days',\n",
    " 'enrolled_30_days',\n",
    " 'enrolled_60_days',\n",
    " 'enrolled_90_days',\n",
    " 'accounts_day_0',\n",
    " 'accounts_7_days',\n",
    " 'accounts_30_days',\n",
    " 'accounts_60_days',\n",
    " 'accounts_90_days', \n",
    "'applied', \n",
    "'funded_1_days',\n",
    " 'funded_2_days',\n",
    " 'funded_3_days',\n",
    " 'funded_7_days',\n",
    " 'funded_30_days',\n",
    " 'funded_60_days',\n",
    " 'funded_90_days', \n",
    "'day_1_balance',\n",
    " 'day_2_balance',\n",
    " 'day_3_balance',\n",
    " 'day_7_balance',\n",
    " 'day_30_balance',\n",
    " 'day_60_balance',\n",
    " 'day_90_balance'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['application_month',\n",
       " 'application_week',\n",
       " 'applied_date',\n",
       " 'mkt_channel',\n",
       " 'source',\n",
       " 'campaign_id',\n",
       " 'impressions',\n",
       " 'clicks',\n",
       " 'spend',\n",
       " 'non_unique_traffic',\n",
       " 'traffic',\n",
       " 'hit_idv',\n",
       " 'enrolled_day_0',\n",
       " 'funded_day_0',\n",
       " 'day_0_balance',\n",
       " 'Index_Match ID',\n",
       " 'Tableau_Impressions',\n",
       " 'Tableau_Clicks',\n",
       " 'Tableau_Cost',\n",
       " 'Media Category',\n",
       " 'Paid Search  SubCategory',\n",
       " 'Intent',\n",
       " 'Target Audeince',\n",
       " 'Pre/Post BLMA',\n",
       " 'Post BLMA: Phases',\n",
       " 'Cost_All-In',\n",
       " 'Clicks_All-In',\n",
       " 'Weekday',\n",
       " 'Custom Date Range',\n",
       " '1/2 Months Intervals',\n",
       " 'Match Type',\n",
       " 'Device Type',\n",
       " 'applied_Year',\n",
       " 'applied_Month',\n",
       " 'applied_Week',\n",
       " 'applied_Day',\n",
       " 'applied_Dayofweek',\n",
       " 'applied_Dayofyear',\n",
       " 'applied_Days_in_month',\n",
       " 'applied_is_leap_year',\n",
       " 'applied_Is_month_end',\n",
       " 'applied_Is_month_start',\n",
       " 'applied_Is_quarter_end',\n",
       " 'applied_Is_quarter_start',\n",
       " 'applied_Is_year_end',\n",
       " 'applied_Is_year_start']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_v2.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Target Data Variables for Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_funded= simple_v2['funded_day_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_balance= simple_v2['day_0_balance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_v2.drop(['funded_day_0','day_0_balance'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "obj_cols = simple_v2.select_dtypes(['object']).columns\n",
    "simple_v3 = simple_v2.drop(obj_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_v3.drop(['applied_date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_v3.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_funded.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing Dataset Into 'Testing Data' & 'Training Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into a training and testing set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Extracting the target variable without encoding(we will have 2 for this dataset)\n",
    "\n",
    "train_on= simple_v3\n",
    "train_label= target_funded\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_on, train_label, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Machine Learning Algorithm to Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_model = RandomForestRegressor(n_jobs=-1, random_state=0)\n",
    "rf_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Target Variable ~ 'Accounts Funded' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0. , 0.9, ..., 0. , 0. , 0. ])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Performance of Machine Learning Predictive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category = RuntimeWarning)\n",
    "\n",
    "def metrics(train_pred, valid_pred, y_train, y_valid):\n",
    "    \"\"\"Calculate metrics: Root mean squared error and mean absolute percentage error\"\"\"\n",
    "    \n",
    "    # Root mean squared error\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))\n",
    "    valid_rmse = np.sqrt(mean_squared_error(y_valid, valid_pred))\n",
    "    \n",
    "    # Calculate absolute percentage error\n",
    "    train_ape = abs((y_train - train_pred) / y_train)\n",
    "    valid_ape = abs((y_valid - valid_pred) / y_valid)\n",
    "    \n",
    "    # Account for y values of 0\n",
    "    train_ape[train_ape == np.inf] = 0\n",
    "    train_ape[train_ape == -np.inf] = 0\n",
    "    valid_ape[valid_ape == np.inf] = 0\n",
    "    valid_ape[valid_ape == -np.inf] = 0\n",
    "    \n",
    "    train_mape = 100 * np.mean(train_ape)\n",
    "    valid_mape = 100 * np.mean(valid_ape)\n",
    "    \n",
    "    return train_rmse, valid_rmse, train_mape, valid_mape\n",
    "\n",
    "def evaluate(model, features, X_train, X_valid, y_train, y_valid):\n",
    "    \"\"\"Mean absolute percentage error\"\"\"\n",
    "    \n",
    "    # Make predictions\n",
    "    train_pred = model.predict(X_train[features])\n",
    "    valid_pred = model.predict(X_valid[features])\n",
    "    \n",
    "    # Get metrics\n",
    "    train_rmse, valid_rmse, train_mape, valid_mape = metrics(train_pred, valid_pred,\n",
    "                                                             y_train, y_valid)\n",
    "    print(f'Training:   rmse = {round(train_rmse, 2)} \\t mape = {round(train_mape, 2)}')\n",
    "    print(f'Validation: rmse = {round(valid_rmse, 2)} \\t mape = {round(valid_mape, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presenting the Accuracy of Future Funded Accounts for 'Simple.com Bank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:   rmse = 0.14 \t mape = 11.19\n",
      "Validation: rmse = 0.33 \t mape = 20.36\n"
     ]
    }
   ],
   "source": [
    "# Reviewing our linear regression model\n",
    "evaluate(rf_model, x_train.columns , x_train, x_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
